{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c28641",
   "metadata": {},
   "source": [
    "# Sistemas Especialistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22eef052",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_conhecimento = {\n",
    "    \"sol\": {\n",
    "        \"quente\": \"Ir à Praia\",\n",
    "        \"ameno\": \"Fazer uma caminhada no parque\",\n",
    "    },\n",
    "    \"nublado\": {\n",
    "        \"quente\": \"Visitar um parente com ar condicionado\",\n",
    "        \"ameno\": \"Ficar em casa e tomar café\",\n",
    "    },\n",
    "    \"chuva\": {\n",
    "        \"quente\": \"Ficar na chuva\",\n",
    "        \"ameno\": \"Ficar em casa comendo pipoca\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744b6ef",
   "metadata": {},
   "source": [
    "## Motor de inferência (Simples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58111809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motor_inferencia_clima(fatos):\n",
    "    clima = fatos.get(\"clima\")\n",
    "    temperatura = fatos.get(\"temperatura\")\n",
    "    \n",
    "    if clima in base_conhecimento and temperatura in base_conhecimento[clima]:\n",
    "        return base_conhecimento[clima][temperatura]\n",
    "    else:\n",
    "        return \"Não tenho recomendação para essa combinação de clima e temperatura.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3156d42",
   "metadata": {},
   "source": [
    "## Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatos: {'clima': 'chuva', 'temperatura': 'quente'}\n",
      "Conclusão: Ficar na chuva\n"
     ]
    }
   ],
   "source": [
    "fatos = {\n",
    "    \"clima\": \"chuva\",\n",
    "    \"temperatura\": \"quente\"\n",
    "}\n",
    "\n",
    "conclusao = motor_inferencia_clima(fatos)\n",
    "print(f\"Fatos: {fatos}\")\n",
    "print(f\"Conclusão: {conclusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842068a",
   "metadata": {},
   "source": [
    "# Forward e Backward Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03190b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fatos = [\"tem_pelos\", \"voa\", \"produz_leite\"]\n",
    "regras = [\n",
    "    {\n",
    "        \"se\": [\"tem_penas\", \"voa\"],\n",
    "        \"entao\": \"e_passaro\"\n",
    "    },\n",
    "    {\n",
    "        \"se\": [\"tem_penas\", \"pode_cantar\"],\n",
    "        \"entao\": \"e_canario\"\n",
    "    },\n",
    "    {\n",
    "        \"se\": [\"tem_pelos\", \"produz_leite\"],\n",
    "        \"entao\": \"e_mamifero\"\n",
    "    },\n",
    "    {\n",
    "        \"se\": [\"tem_pelos\", \"voa\"],\n",
    "        \"entao\": \"e_morcego\"\n",
    "    },\n",
    "    {\n",
    "        \"se\": [\"tem_pelos\", \"pode_cantar\"],\n",
    "        \"entao\": \"e_pirata\"\n",
    "    },\n",
    "    {\n",
    "        \"se\": [\"tem_pelos\", \"late\"],\n",
    "        \"entao\": \"e_cachorro\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca02fc",
   "metadata": {},
   "source": [
    "## Motor de inferência (Forward Chaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c13803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motor_inferencia_forward(fatos_init, regras):\n",
    "    fatos_derivados = list(fatos_init)\n",
    "    novo_fato = True\n",
    "    \n",
    "    while novo_fato:\n",
    "        novo_fato = False\n",
    "        for regra in regras:\n",
    "            condicao_satisfeita = all(condicao in fatos_derivados for condicao in regra[\"se\"])\n",
    "            \n",
    "            if condicao_satisfeita and regra[\"entao\"] not in fatos_derivados:\n",
    "                fatos_derivados.append(regra[\"entao\"])\n",
    "                print(f\"Regra disparada: SE {regra['se']} ENTAO {regra['entao']}\")\n",
    "                print(f\"Fato adicionado: {regra['entao']}\")\n",
    "                novo_fato = True\n",
    "                \n",
    "    return fatos_derivados           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5154b2",
   "metadata": {},
   "source": [
    "## Simulação (Forward Chaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b63d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatos iniciais: ['tem_pelos', 'voa', 'produz_leite']\n",
      "Regra disparada: SE ['tem_pelos', 'produz_leite'] ENTAO e_mamifero\n",
      "Fato adicionado: e_mamifero\n",
      "Regra disparada: SE ['tem_pelos', 'voa'] ENTAO e_morcego\n",
      "Fato adicionado: e_morcego\n",
      "Fatos finais: ['tem_pelos', 'voa', 'produz_leite', 'e_mamifero', 'e_morcego']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fatos iniciais: {fatos}\")\n",
    "fatos_finais = motor_inferencia_forward(fatos, regras)\n",
    "print(f\"Fatos finais: {fatos_finais}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
